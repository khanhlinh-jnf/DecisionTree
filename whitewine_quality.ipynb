{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import graphviz\n",
    "from IPython.display import display, Markdown\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "project_dir = os.getcwd()\n",
    "graphviz_bin_path = os.path.join(project_dir, \"bin\")\n",
    "os.environ[\"PATH\"] += os.pathsep + graphviz_bin_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959d762",
   "metadata": {},
   "source": [
    "# Read data from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/winequality-white.csv'\n",
    "data = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "def classify_quality(quality):\n",
    "    if quality <= 4:\n",
    "        return 'Low'\n",
    "    elif quality <= 6:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "features = data.drop('quality', axis=1)\n",
    "labels = data['quality'].apply(classify_quality)\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Samples: {len(data)}, Features: {len(features.columns)}\")\n",
    "print(\"\\nQuality distribution:\")\n",
    "print(labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25ca7d",
   "metadata": {},
   "source": [
    "# Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56393216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stratified_splits(features, labels, test_sizes):\n",
    "    splits = {}\n",
    "    for test_size in test_sizes:\n",
    "        feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "            features, labels, \n",
    "            test_size=test_size, \n",
    "            random_state=42,\n",
    "            stratify=labels\n",
    "        )\n",
    "        split_name = f\"train_{100-int(test_size*100)}_test_{int(test_size*100)}\"\n",
    "        splits[split_name] = {\n",
    "            'feature_train': feature_train,\n",
    "            'label_train': label_train,\n",
    "            'feature_test': feature_test,\n",
    "            'label_test': label_test\n",
    "        }\n",
    "    return splits\n",
    "\n",
    "test_sizes = [0.6, 0.4, 0.2, 0.1]\n",
    "splits = create_stratified_splits(features, labels, test_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d8699",
   "metadata": {},
   "source": [
    "# Visualize the class distributions in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce627289",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 12))\n",
    "plt.subplot(3, 2, 1)\n",
    "labels.value_counts().plot(kind='bar')\n",
    "plt.title('Original Distribution')\n",
    "\n",
    "for i, (name, data) in enumerate(splits.items(), 2):\n",
    "    plt.subplot(3, 2, i)\n",
    "    data['label_train'].value_counts().plot(kind='bar', alpha=0.6, label='Train')\n",
    "    data['label_test'].value_counts().plot(kind='bar', alpha=0.6, label='Test')\n",
    "    plt.title(name.replace('_', ' '))\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097dea0",
   "metadata": {},
   "source": [
    "# Building the decision tree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tree(feature_train, label_train, feature_test, label_test, max_depth=None):\n",
    "    dt = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=42)\n",
    "    dt.fit(feature_train, label_train)\n",
    "    predictions = dt.predict(feature_test)\n",
    "\n",
    "    dot_data = export_graphviz(\n",
    "        dt,\n",
    "        out_file=None,\n",
    "        feature_names=feature_train.columns,\n",
    "        class_names=[str(x) for x in sorted(label_train.unique())],\n",
    "        filled=True,\n",
    "        rounded=True\n",
    "    )\n",
    "    display(graphviz.Source(dot_data))\n",
    "\n",
    "    report = classification_report(label_test, predictions, target_names=sorted(label_train.unique()))\n",
    "    acc = accuracy_score(label_test, predictions)\n",
    "    cm = confusion_matrix(label_test, predictions, labels=sorted(label_train.unique()))\n",
    "    \n",
    "    display(Markdown(f\"### ðŸ“‹ Classification Report\"))\n",
    "    print(report)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "\n",
    "    display(Markdown(f\"### ðŸ“Š Confusion Matrix\"))\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='rocket_r',\n",
    "                xticklabels=sorted(label_train.unique()), yticklabels=sorted(label_train.unique()))\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Decision Tree Classifier confusion matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8a674",
   "metadata": {},
   "source": [
    "#  Evaluating the decision tree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dae705",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating all splits...\")\n",
    "for name, split in splits.items():\n",
    "    print(f\"\\n{'-'*50}\\nEvaluating {name.replace('_', ' ')}\")\n",
    "    evaluate_tree(\n",
    "        split['feature_train'], \n",
    "        split['label_train'],\n",
    "        split['feature_test'],\n",
    "        split['label_test']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630284f5",
   "metadata": {},
   "source": [
    "# The depth and accuracy of a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147689ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nAnalyzing max_depth for 80/20 split...\")\n",
    "X_train = splits['train_80_test_20']['feature_train']\n",
    "y_train = splits['train_80_test_20']['label_train']\n",
    "X_test = splits['train_80_test_20']['feature_test']\n",
    "y_test = splits['train_80_test_20']['label_test']\n",
    "\n",
    "max_depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "accuracies = []\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "for i, depth in enumerate(max_depths, 1):\n",
    "    plt.subplot(4, 2, i)\n",
    "    dt = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    acc = dt.score(X_test, y_test)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    plot_tree(dt, feature_names=features.columns, filled=True)\n",
    "    plt.title(f\"max_depth={depth}\\nAccuracy: {acc:.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c19cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nmax_depth\\tAccuracy\")\n",
    "for depth, acc in zip(max_depths, accuracies):\n",
    "    print(f\"{str(depth).ljust(8)}\\t{acc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([str(d) if d else 'None' for d in max_depths], accuracies, 'o-')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs max_depth')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
